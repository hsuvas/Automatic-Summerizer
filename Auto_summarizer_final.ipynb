{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_table(text_string) -> dict:\n",
    "\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps=WordNetLemmatizer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word=ps.lemmatize(word)\n",
    "        if word not in stopWords:\n",
    "            if word in freqTable:\n",
    "                freqTable[word] += 1\n",
    "            else:\n",
    "                freqTable[word] = 1\n",
    "    return freqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(sentences, freqTable) -> dict:\n",
    "    sentenceValue = dict()\n",
    "\n",
    "    for sent in sentences:\n",
    "        word_count_in_sentence = (len(word_tokenize(sent)))\n",
    "        for wordValue in freqTable:\n",
    "            if wordValue in sent.lower():\n",
    "                if sent in sentenceValue:\n",
    "                    sentenceValue[sent] += freqTable[wordValue]\n",
    "                else:\n",
    "                    sentenceValue[sent] = freqTable[wordValue]    \n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_high_score(sent,sentVal,n)->dict:\n",
    "    result = {}\n",
    "    for key in sorted(sentVal, key=sentVal.get, reverse=True)[:n]:\n",
    "        result.update({key: sentVal[key]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_summary(sentences,summ,n):\n",
    "    summary=''\n",
    "    sentence_count=0\n",
    "    for sentence in sentences[:n]:\n",
    "        if sentence in summ:\n",
    "            summary+=\" \"+sentence\n",
    "            sentence_count+=1\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in how many sentences do you want the summary?6\n",
      " To obtain information on any concerns members of the university community may be having with air quality in work and study environments , the consultants designed a questionnaire and placed it on a web site provided by the Department of Computing and Communications . The on-line questionnaire was publicized in The Gazette and The Muse and by notices on campus bulletin boards . A total of 520 responses were received . Additional information on air quality in areas identified in responses to the que stionnaire was gathered through measurements of temperature , humidity , carbon dioxide and molds . In addition , teams of investigators , accompanied by officials from Facilities Management , conducted a survey of the entire campus as well as buildings on Mount Scio Road and the Ocean Sciences Centre at Logy Bay . These survey teams identified all items of environmental concern , including items that could have an effect on the air quality of the buildings .\n"
     ]
    }
   ],
   "source": [
    "f=open(\"F:\\\\1A_en_UMBC_tokenized(1)\\\\UMBC_tokenized.txt\",encoding=\"Latin-1\")\n",
    "text=f.read(1000000)\n",
    "\n",
    "freq_table =_create_frequency_table(text)\n",
    "sentences=sent_tokenize(text)\n",
    "n=int(input(\"in how many sentences do you want the summary?\"))\n",
    "sent=sentences[:n]\n",
    "sent_score=_score_sentences(sent, freq_table)\n",
    "\n",
    "summ=_find_high_score(sent,sent_score,n)\n",
    "\n",
    "summary=_gen_summary(sentences,summ,n)\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
